{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import scipy \n",
    "import scipy.stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_in_data(behav_data_f):\n",
    "    \"\"\"\n",
    "    Read in the data\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(behav_data_f)\n",
    "    df = df.loc[df['func_perc_fd'].notnull(), :]\n",
    "    df = df.loc[df['FILE_ID']!='no_filename', :]\n",
    "    df['AGE_YRS'] = np.floor(df['AGE_AT_SCAN'])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def split_half_outcome(df, motion_thresh, age_l, age_u, n, n_perms=100):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function returns the R squared of how each parameter affects split-half reliability!\n",
    "    It takes in a dataframe, motion threshold, an age upper limit(age_u) an age lower limit (age_l), sample size (n),\n",
    "    and number of permutations (n_perms, currently hard coded at 100). This function essentially splits a data frame \n",
    "    into two matched samples (split_two_matched_samples.py), then creates mean roi-roi correlation matrices per sample \n",
    "    (make_group_corr_mat.py) and then calculates the R squared (calc_rsq.py) between the two samples'\n",
    "    correlation matrices and returns all the permuation coefficients of determinations in a dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    #set up data frame of average R squared to fill up later\n",
    "    Rsq_list = []\n",
    "    ICC_list = []\n",
    "    ## set up age-motion corr dfs\n",
    "    r_a_list=[]\n",
    "    p_a_list=[]\n",
    "    r_b_list=[]\n",
    "    p_b_list=[]\n",
    "    \n",
    "    #Do this in each permutation\n",
    "    for i in range(n_perms):\n",
    "        #create two matched samples split on motion_thresh, age upper, age lower, and n\n",
    "        df_A, df_B = split_two_matched_samples(df, motion_thresh, age_l, age_u, n)\n",
    "        #make the matrix of all subjects roi-roi correlations, make the mean corr mat, and make covariance cor mat\n",
    "        #do this for A and then B\n",
    "        all_corr_mat_A, age_roi_corr_A = make_group_corr_mat(df_A)\n",
    "        all_corr_mat_B, age_roi_corr_B = make_group_corr_mat(df_B)\n",
    "        \n",
    "        #calculate the R squared between the two matrices\n",
    "        Rsq = calc_rsq(age_roi_corr_A, age_roi_corr_B)\n",
    "        \n",
    "        #calculate the ICC between the two matrices\n",
    "        ICC = compute_icc(age_roi_corr_A, age_roi_corr_B)\n",
    "        \n",
    "        print (\"Iteration \" + str(i) + \": R^2 = \" + str(Rsq) + \", ICC = \" + str(ICC))\n",
    "        \n",
    "        #build up R squared output\n",
    "        Rsq_list += [Rsq]\n",
    "        ICC_list += [ICC]\n",
    "\n",
    "\n",
    "        #check if age and motion are correlated\n",
    "        age=df_A[\"AGE_AT_SCAN\"]\n",
    "        motion=df_A[\"func_perc_fd\"]\n",
    "        r_a,p_a=scipy.stats.pearsonr(age, motion) #returns r and p\n",
    "    \n",
    "        age=df_B[\"AGE_AT_SCAN\"]\n",
    "        motion=df_B[\"func_perc_fd\"]\n",
    "        r_b,p_b=scipy.stats.pearsonr(age, motion) #returns r and p\n",
    "\n",
    "        #build up R and p output\n",
    "        r_a_list += [r_a]\n",
    "        p_a_list += [p_a]\n",
    "        r_b_list += [r_b]\n",
    "        p_b_list += [p_b]\n",
    "    \n",
    "    return np.array(Rsq_list), np.array(ICC_list), np.array(r_a_list), np.array(p_a_list),np.array(r_b_list), np.array(p_b_list)\n",
    "\n",
    "def calc_rsq(av_corr_mat_A, av_corr_mat_B):\n",
    "    \"\"\"\n",
    "    From wikipedia: https://en.wikipedia.org/wiki/Coefficient_of_determination\n",
    "    \n",
    "    Rsq = 1 - (SSres / SStot)\n",
    "    \n",
    "    SSres is calculated as the sum of square errors (where the error\n",
    "    is the difference between x and y).\n",
    "    \n",
    "    SStot is calculated as the total sum of squares in y.\n",
    "    \"\"\"\n",
    "    # Get the data we need\n",
    "    inds = np.triu_indices_from(av_corr_mat_B, k=1)\n",
    "    x = av_corr_mat_A[inds]\n",
    "    y = av_corr_mat_B[inds]\n",
    "    \n",
    "    # Calculate the error/residuals\n",
    "    res = y - x\n",
    "\n",
    "    SSres = np.sum(res**2)\n",
    "    \n",
    "    # Sum up the total error in y\n",
    "    y_var = y - np.mean(y)\n",
    "    \n",
    "    SStot = np.sum(y_var**2)\n",
    "    \n",
    "    # R squared\n",
    "    Rsq = 1 - (SSres/SStot)\n",
    "    \n",
    "    return Rsq\n",
    "\n",
    "def exclude_nan(x,y):\n",
    "    \"\"\"\n",
    "    Exclude NaN values if either entry in a pair of vectors has NaN\n",
    "    \"\"\"\n",
    "    idx = np.logical_not(np.logical_or(np.isnan(x), np.isnan(y)))\n",
    "    x = x[idx]\n",
    "    y = y[idx]\n",
    "    n = len(x)\n",
    "    return [x, y, n]\n",
    "\n",
    "def compute_icc(av_corr_mat_A, av_corr_mat_B):\n",
    "    \"\"\"\n",
    "    This function computes the inter-class correlation (ICC) of the\n",
    "    two classes represented by the x and y numpy vectors.\n",
    "    from: http://stats.stackexchange.com/questions/63368/intra-class-correlation-and-experimental-design\n",
    "    and: Shrout, P. E., & Fleiss, J. L. (1979). Intraclass Correlations: Uses\n",
    "    in Assessing Rater Reliability. Psychological Bulletin, 86(2), 420-428. http://rokwa.x-y.net/Shrout-Fleiss-ICC.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    inds = np.triu_indices_from(av_corr_mat_B, k=1)\n",
    "    x = av_corr_mat_A[inds]\n",
    "    y = av_corr_mat_B[inds]\n",
    "    \n",
    "    if all(x == y):\n",
    "        return 1\n",
    "\n",
    "    [x, y, n] = exclude_nan(x,y)\n",
    "\n",
    "    ## Need at least 3 data points to compute this\n",
    "    if n < 3:\n",
    "        return np.nan\n",
    "\n",
    "    Sx = sum(x); Sy = sum(y);\n",
    "    Sxx = sum(x*x); Sxy = sum( (x+y)**2 )/2; Syy = sum(y*y)\n",
    "\n",
    "    fact = ((Sx + Sy)**2)/(n*2)\n",
    "    SS_tot = Sxx + Syy - fact\n",
    "    SS_among = Sxy - fact\n",
    "    SS_error = SS_tot - SS_among\n",
    "\n",
    "    MS_error = SS_error/n\n",
    "    MS_among = SS_among/(n-1)\n",
    "    ICC = (MS_among - MS_error) / (MS_among + MS_error)\n",
    "\n",
    "    return ICC\n",
    "\n",
    "def make_group_corr_mat(df):\n",
    "    \"\"\"\n",
    "    This function reads in each subject's aal roi time series files and creates roi-roi correlation matrices\n",
    "    for each subject and then sums them all together. This creates  a 3d matrix of all subjects \n",
    "    roi-roi correlations. These correlations are Z scored. Then each roi-roi Z-scored correlation is correlated with age \n",
    "    across all subjects. The output of this function is aa 3d matrix of all subjects roi-roi correlations\n",
    "    and a 2d matrix of r values for each roi-roi correlation with age.  \n",
    "    \"\"\"\n",
    "\n",
    "    # for each subject do the following\n",
    "    \n",
    "    for i, (sub, f_id) in enumerate(df[['SUB_ID', 'FILE_ID']].values):\n",
    "        \n",
    "        #read each subjects aal roi time series files\n",
    "        ts_df = pd.read_table('DATA/{}_rois_aal.1D'.format(f_id))\n",
    "\n",
    "        #create a correlation matrix from the roi all time series files\n",
    "        corr_mat_r = ts_df.corr()\n",
    "        #the correlations need to be transformed to Fisher z, which is\n",
    "        #equivalent to the arctanh function.\n",
    "        corr_mat_z = np.arctanh(corr_mat_r)\n",
    "        \n",
    "        #for the first subject, add a correlation matrix of zeros that is the same dimensions as the aal roi-roi matrix\n",
    "        if i == 0:\n",
    "            all_corr_mat = np.zeros([corr_mat_z.shape[0], corr_mat_z.shape[1], len(df)])\n",
    "\n",
    "        #now add the correlation matrix you just created for each subject to the all_corr_mat matrix (3D)\n",
    "        all_corr_mat[:, :, i] = corr_mat_z\n",
    "\n",
    "\t##now correlate with age for each matrix\n",
    "    age=df.loc[:, 'AGE_AT_SCAN']\n",
    "    age_df=pd.DataFrame(age)\n",
    "    age_df.index=[x for x in range(age_df.shape[0])]\n",
    "    age_roi_corr =np.ones((116,116))\n",
    "    for  r in range(all_corr_mat.shape[0]):\n",
    "            for rn in range(all_corr_mat.shape[0]):\n",
    "                if rn != r:\n",
    "                    corr_dat=pd.DataFrame(all_corr_mat[r,rn,:])\n",
    "                    corr_dat[\"age\"]=age_df\n",
    "                    age_roi_corr[r,rn]=corr_dat.corr()[\"age\"][0]\n",
    "    \n",
    "    #create the mean correlation matrix (ignore nas - sometime there are some...)\n",
    "    #av_corr_mat = np.nanmean(all_corr_mat, axis=2)\n",
    "    #create the group covariance matrix (ignore nas - sometime there are some...)\n",
    "    #var_corr_mat = np.nanvar(all_corr_mat, axis=2)\n",
    "        \n",
    "    return all_corr_mat, age_roi_corr\n",
    "\n",
    "def split_two_matched_samples(df, motion_thresh, age_l, age_u, n):\n",
    "    \"\"\"\n",
    "    This function takes in a data frame, thresholds it to only include\n",
    "    participants whose percentage bad frames are less than motion_thresh\n",
    "    and participants who are between the lower and upper age limits (inclusive),\n",
    "    then returns two matched samples of size n. The samples are matched on\n",
    "    age in years, autism diagnosis, gender and scanning site. This function also selectively samples the\n",
    "    func_perc_fd\n",
    "    Information about the motion measure is here:\n",
    "    http://preprocessed-connectomes-project.org/quality-assessment-protocol/\n",
    "    \"\"\"\n",
    "    \n",
    "    # Start by removing all participants whose data is below a certain\n",
    "    # motion threshold.\n",
    "    df_samp_motion =  df.loc[df['func_perc_fd'] < motion_thresh, :]\n",
    "\n",
    "    # Then remove participants who are younger (in years) than age_l and older\n",
    "    # than age_u. Note that this means people who are age_l and age_u\n",
    "    # (eg 6 and 10) will be included in the sample.\n",
    "    df_samp = df_samp_motion.loc[(df_samp_motion['AGE_YRS']>=age_l)\n",
    "                                    & (df_samp_motion['AGE_YRS']<=age_u), :]\n",
    "                                    \n",
    "    ##sort subjects based on motion\n",
    "    sort_column_list = ['func_perc_fd']\n",
    "    df_motion_sorted = df_samp.sort_values(by=sort_column_list)\n",
    "    \n",
    "    ##rank subjects by motion\n",
    "    r=range(len(df_motion_sorted))\n",
    "    r_df=pd.DataFrame(r)\n",
    "    r_df.columns = ['rank']\n",
    "    r_df['newcol'] = df_motion_sorted.index\n",
    "    r_df.set_index('newcol', inplace=True)\n",
    "    r_df.index.names = [None]\n",
    "    df_motion_sorted_rank=pd.concat ([r_df,df_motion_sorted], axis=1)\n",
    "    \n",
    "    ##create bins of subjects in quartiles\n",
    "    l=len(df_motion_sorted_rank)\n",
    "    chunk=l/4\n",
    "    chunk1=chunk\n",
    "    chunk2=2*chunk\n",
    "    chunk3=3*chunk\n",
    "    chunk4=l\n",
    "    \n",
    "    first=df_motion_sorted_rank[df_motion_sorted_rank['rank']<=chunk1]\n",
    "    second=df_motion_sorted_rank[(df_motion_sorted_rank['rank']>chunk1) & (df_motion_sorted_rank['rank']<=chunk2)]\n",
    "    third=df_motion_sorted_rank[(df_motion_sorted_rank['rank']>chunk2) & (df_motion_sorted_rank['rank']<=chunk3)]\n",
    "    fourth=df_motion_sorted_rank[df_motion_sorted_rank['rank']>=chunk3]\n",
    "    \n",
    "    ##take 2n/4 from each bin\n",
    "    n_samp=(n*2)/4\n",
    "    n_samp\n",
    "    n_samp=int(n_samp)\n",
    "\n",
    "    # Shuffle these remaining participants to ensure you get different sub\n",
    "    # samples each time you run the code.\n",
    "    first_rand = first.reindex(np.random.permutation(first.index))\n",
    "    second_rand = second.reindex(np.random.permutation(second.index))\n",
    "    third_rand = third.reindex(np.random.permutation(third.index))\n",
    "    fourth_rand = fourth.reindex(np.random.permutation(fourth.index))\n",
    "\n",
    "    # Only keep the top 2*n/4 participants.\n",
    "    first_samp_2n = first_rand.iloc[:n_samp, :]\n",
    "    second_samp_2n = second_rand.iloc[:n_samp, :]\n",
    "    third_samp_2n = third_rand.iloc[:n_samp, :]\n",
    "    fourth_samp_2n = fourth_rand.iloc[:n_samp, :]\n",
    "    \n",
    "    #append these together\n",
    "    frames = [first_samp_2n, second_samp_2n, third_samp_2n,fourth_samp_2n]\n",
    "    final_df = pd.concat(frames)\n",
    "\n",
    "    # Sort these participants according to the sort columns of interest\n",
    "    sort_column_list = ['DSM_IV_TR', 'DX_GROUP', 'SITE_ID', 'SEX', 'AGE_YRS']\n",
    "    df_samp_2n_sorted = final_df.sort_values(by=sort_column_list)\n",
    "\n",
    "    # Now put all even numbered participants in group A and all odd numbered\n",
    "    # participants in group B.\n",
    "    df_grp_A = df_samp_2n_sorted.iloc[::2, :]\n",
    "    df_grp_B = df_samp_2n_sorted.iloc[1::2, :]\n",
    "\n",
    "    # Boom! Return these two data frames\n",
    "    return df_grp_A, df_grp_B\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def abide_motion_wrapper(motion_thresh, age_l, age_u, n, n_perms=1000, overwrite=True):\n",
    "    behav_data_f = '../../Phenotypic_V1_0b_preprocessed1.csv'\n",
    "       \n",
    "    f_name = 'RESULTS_age/rsq_{:03.0f}pct_{:03.0f}subs_{:02.0f}to{:02.0f}.csv'.format(motion_thresh, n, age_l, age_u)\n",
    "    \n",
    "    # By default this code will recreate files even if they already exist\n",
    "    # (overwrite=True)\n",
    "    # If you don't want to do this though, set overwrite to False and \n",
    "    # this step will skip over the analysis if the file already exists\n",
    "    if not overwrite:\n",
    "        # If the file exists then skip this loop\n",
    "        if os.path.isfile(f_name):\n",
    "            return\n",
    "    \n",
    "    df = read_in_data(behav_data_f)\n",
    "\n",
    "    rsq_list, icc_list, r_a_list, p_a_list, r_b_list, p_b_list = split_half_outcome(df, motion_thresh, age_l, age_u, n, n_perms=n_perms)\n",
    "    \n",
    "    \n",
    "    print (\"R Squared list shape: \" + str(rsq_list.shape))\n",
    "    print (\"ICC list shape: \" + str(icc_list.shape))\n",
    "    \n",
    "    med_rsq = np.median(rsq_list)\n",
    "    rsq_CI = np.percentile(rsq_list, 97.5) - np.percentile(rsq_list, 2.5)\n",
    "    \n",
    "    med_icc = np.median(icc_list)\n",
    "    icc_CI = np.percentile(icc_list, 97.5) - np.percentile(icc_list, 2.5)\n",
    "\n",
    "    med_r_a = np.median(r_a_list)\n",
    "    med_p_a = np.median(p_a_list)\n",
    "    med_r_b = np.median(r_b_list)\n",
    "    med_p_b = np.median(p_b_list)\n",
    "\n",
    "\n",
    "    columns = [ 'motion_thresh', 'age_l', 'age_u', 'n', 'med_rsq', 'CI_95', 'med_icc', 'CI_95_icc','med_age_motion_r_a','med_age_motion_p_a','med_age_motion_r_b','med_age_motion_p_b' ]\n",
    "    results_df = pd.DataFrame(np.array([[motion_thresh, age_l, age_u, n, med_rsq, rsq_CI, med_icc, icc_CI, med_r_a, med_p_a, med_r_b, med_p_b ]]), \n",
    "                                  columns=columns)\n",
    "\n",
    "\n",
    "    results_df.to_csv(f_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "behav_data_f = '../../Phenotypic_V1_0b_preprocessed1.csv'\n",
    "df = pd.read_csv(behav_data_f)\n",
    "df = df.loc[df['func_perc_fd'].notnull(), :]\n",
    "df = df.loc[df['FILE_ID']!='no_filename', :]\n",
    "df['AGE_YRS'] = np.floor(df['AGE_AT_SCAN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_A, df_B = split_two_matched_samples(df, 50, 6, 18, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om/user/jlnrd/py27/lib/python2.7/site-packages/ipykernel/__main__.py:169: RuntimeWarning: divide by zero encountered in arctanh\n"
     ]
    }
   ],
   "source": [
    "all_corr_mat_A, age_roi_corr_A = make_group_corr_mat(df_A)\n",
    "all_corr_mat_B, age_roi_corr_B = make_group_corr_mat(df_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116, 116)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_roi_corr_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_half_outcome(df, motion_thresh, age_l, age_u, n, n_perms=100):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function returns the R squared of how each parameter affects split-half reliability!\n",
    "    It takes in a dataframe, motion threshold, an age upper limit(age_u) an age lower limit (age_l), sample size (n),\n",
    "    and number of permutations (n_perms, currently hard coded at 100). This function essentially splits a data frame \n",
    "    into two matched samples (split_two_matched_samples.py), then creates mean roi-roi correlation matrices per sample \n",
    "    (make_group_corr_mat.py) and then calculates the R squared (calc_rsq.py) between the two samples'\n",
    "    correlation matrices and returns all the permuation coefficients of determinations in a dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    #set up data frame of average R squared to fill up later\n",
    "    Rsq_list = []\n",
    "    ICC_list = []\n",
    "    ## set up age-motion corr dfs\n",
    "    r_a_list=[]\n",
    "    p_a_list=[]\n",
    "    r_b_list=[]\n",
    "    p_b_list=[]\n",
    "    \n",
    "    #Do this in each permutation\n",
    "    for i in range(n_perms):\n",
    "        #create two matched samples split on motion_thresh, age upper, age lower, and n\n",
    "        df_A, df_B = split_two_matched_samples(df, motion_thresh, age_l, age_u, n)\n",
    "        #make the matrix of all subjects roi-roi correlations, make the mean corr mat, and make covariance cor mat\n",
    "        #do this for A and then B\n",
    "        all_corr_mat_A, age_roi_corr_A = make_group_corr_mat(df_A)\n",
    "        all_corr_mat_B, age_roi_corr_B = make_group_corr_mat(df_B)\n",
    "        \n",
    "        #calculate the R squared between the two matrices\n",
    "        Rsq = calc_rsq(age_roi_corr_A, age_roi_corr_B)\n",
    "        \n",
    "        #calculate the ICC between the two matrices\n",
    "        ICC = compute_icc(age_roi_corr_A, age_roi_corr_B)\n",
    "        \n",
    "        print (\"Iteration \" + str(i) + \": R^2 = \" + str(Rsq) + \", ICC = \" + str(ICC))\n",
    "        \n",
    "        #build up R squared output\n",
    "        Rsq_list += [Rsq]\n",
    "        ICC_list += [ICC]\n",
    "\n",
    "\n",
    "        #check if age and motion are correlated\n",
    "        age=df_A[\"AGE_AT_SCAN\"]\n",
    "        motion=df_A[\"func_perc_fd\"]\n",
    "        r_a,p_a=scipy.stats.pearsonr(age, motion) #returns r and p\n",
    "    \n",
    "        age=df_B[\"AGE_AT_SCAN\"]\n",
    "        motion=df_B[\"func_perc_fd\"]\n",
    "        r_b,p_b=scipy.stats.pearsonr(age, motion) #returns r and p\n",
    "\n",
    "        #build up R and p output\n",
    "        r_a_list += [r_a]\n",
    "        p_a_list += [p_a]\n",
    "        r_b_list += [r_b]\n",
    "        p_b_list += [p_b]\n",
    "    \n",
    "    return np.array(Rsq_list), np.array(ICC_list), np.array(r_a_list), np.array(p_a_list),np.array(r_b_list), np.array(p_b_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om/user/jlnrd/py27/lib/python2.7/site-packages/ipykernel/__main__.py:169: RuntimeWarning: divide by zero encountered in arctanh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: R^2 = -0.943162920423, ICC = 0.0999202922312\n",
      "Iteration 1: R^2 = -0.988460409123, ICC = 0.0835285726864\n",
      "Iteration 2: R^2 = -1.70373081319, ICC = -0.154763006887\n",
      "Iteration 3: R^2 = -1.08828607964, ICC = -0.0351962312366\n",
      "Iteration 4: R^2 = -0.823892426984, ICC = 0.0693012890717\n",
      "Iteration 5: R^2 = -0.688549487013, ICC = 0.137746427721\n",
      "Iteration 6: R^2 = -2.70186857605, ICC = -0.298752452624\n",
      "Iteration 7: R^2 = -1.15298939725, ICC = 0.040889359289\n",
      "Iteration 8: R^2 = -1.23753538521, ICC = -0.103724378975\n",
      "Iteration 9: R^2 = -1.15296718905, ICC = 0.0689110991836\n"
     ]
    }
   ],
   "source": [
    "rsq_list, icc_list,r_a_list,p_a_list,r_b_list,p_b_list = split_half_outcome(df, 50, 6, 18, 20, n_perms=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.16745234,  0.81544966,  0.23218532,  0.85965136,  0.33097956,\n",
       "        0.0833455 ,  0.1659351 ,  0.39645775,  0.87851164,  0.31652746])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_a_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.94316292, -0.98846041, -1.70373081, -1.08828608, -0.82389243,\n",
       "       -0.68854949, -2.70186858, -1.1529894 , -1.23753539, -1.15296719])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "med_r_a = np.median(r_a_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.17583394362001187"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_r_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
